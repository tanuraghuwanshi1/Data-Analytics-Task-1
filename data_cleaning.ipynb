{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd609a1b",
   "metadata": {},
   "source": [
    "# Stress Level Dataset â€” Data Cleaning (Task 1)\n",
    "\n",
    "This notebook cleans the raw dataset for the Skillytixs Data Analytics Internship Task 1.\n",
    "It handles duplicates, standardizes text, fixes data types, and saves a cleaned CSV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c88dde",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Load the dataset\n",
    "2. Explore: shape, null counts, duplicates\n",
    "3. Handle missing values (if any)\n",
    "4. Remove duplicates\n",
    "5. Standardize text columns\n",
    "6. Fix data types (numeric/datetime where possible)\n",
    "7. Rename columns to snake_case\n",
    "8. Save cleaned dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_path = \"StressLevelDataset.csv\"          # put the raw CSV next to this notebook\n",
    "clean_path = \"StressLevelDataset_Cleaned.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(raw_path)\n",
    "print(\"Initial shape:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore nulls and duplicates\n",
    "print(\"\\nNull values per column:\\n\", df.isnull().sum())\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (example strategy)\n",
    "# If any nulls exist, forward-fill then back-fill as a simple demo.\n",
    "# Adjust strategy as needed for your dataset.\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    df = df.ffill().bfill()\n",
    "print(\"Nulls after filling:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52557795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "before_dups = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Duplicates removed: {before_dups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a26b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize text columns\n",
    "obj_cols = df.select_dtypes(include=['object']).columns\n",
    "for c in obj_cols:\n",
    "    df[c] = df[c].astype(str).str.strip().str.lower()\n",
    "print(\"Standardized text columns:\", list(obj_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types (try numeric, then datetime)\n",
    "for c in df.columns:\n",
    "    # skip object columns already standardized; attempt numeric first\n",
    "    try:\n",
    "        df[c] = pd.to_numeric(df[c])\n",
    "        continue\n",
    "    except Exception:\n",
    "        pass\n",
    "    # attempt datetime if not numeric\n",
    "    try:\n",
    "        df[c] = pd.to_datetime(df[c], errors='raise')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"Dtypes:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d10920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to snake_case\n",
    "df.columns = (df.columns\n",
    "              .str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(' ', '_')\n",
    "              .str.replace('-', '_')\n",
    "              .str.replace('/', '_'))\n",
    "print(\"Columns renamed:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbca183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "df.to_csv(clean_path, index=False)\n",
    "print(\"Saved:\", clean_path)\n",
    "print(\"Final shape:\", df.shape)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
